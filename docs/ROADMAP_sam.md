# üó∫Ô∏è ROADMAP & GUIDE : Projet MediaFetcher

Ce document sert de plan de bataille pour le d√©veloppement du projet MediaFetcher sur Alpine Linux (LXC/Proxmox).

---

## üõ†Ô∏è PHASE 0 : Pr√©paration & Configuration (Avant de coder)

**Objectif :** Transformer ton environnement et ton VS Code en cockpit de pilotage pour IA.

### 1. Sur le Serveur (LXC Alpine)
- [ ] Mettre √† jour : `apk update && apk upgrade`
- [ ] Installer Docker : `apk add docker docker-cli-compose git`
- [ ] Activer Docker au boot : `rc-update add docker boot && service docker start`
- [ ] Monter le NAS TrueNAS : S'assurer que le dossier `/mnt/media` (ou autre point de montage) est accessible en lecture/√©criture.

### 2. Dans VS Code (Configuration IA)
- [ ] **Fichiers de Contexte :**
    - Cr√©er `GEMINI.md` √† la racine du projet (copie exacte de `docs/CONTEXT_AI.md`).
    - V√©rifier que le dossier `docs/` contient bien `CONTEXT_HUMAN.md` et `CONTEXT_AI.md`.
- [ ] **Extension Codex (OpenAI) :**
    - Aller dans les *Settings* de l'extension.
    - Chercher "System Prompt" ou "Instructions".
    - Coller le r√©sum√© des r√®gles (Alpine, Ref Counting, MP4, TrueNAS).
- [ ] **Extension Gemini :**
    - S'assurer que le fichier `GEMINI.md` est bien d√©tect√© (ou le garder ouvert en permanence).

---

## üèóÔ∏è PHASE 1 : L'Infrastructure (Docker)

**Prompt IA sugg√©r√© (Gemini Agent) :**
> *"En te basant sur GEMINI.md, g√©n√®re l'arborescence du projet et le fichier `docker-compose.yml` complet. Il nous faut : un service Postgres, un service Redis, un container Backend (Python 3.11-slim ou Alpine) et un container Frontend (Node pour le build). N'oublie pas le mapping du volume NAS."*

**Points de vigilance :**
- V√©rifie que le `docker-compose.yml` utilise bien des images l√©g√®res.
- V√©rifie que le volume du NAS est bien mont√© dans le service Backend.

---

## üß† PHASE 2 : Le Backend (Core & Database)

**Objectif :** Cr√©er la logique de "Reference Counting" avant tout le reste.

### 1. Initialisation FastAPI
- [ ] Structure de base FastAPI (main.py, config.py).
- [ ] Connexion DB (SQLAlchemy + Asyncpg).

### 2. Mod√®les de Donn√©es (CRITIQUE)
**Prompt IA sugg√©r√© (Codex ou Gemini) :**
> *"√âcris les mod√®les SQLAlchemy pour `MediaFile` et `LibraryItem` en appliquant strictement la logique de Reference Counting d√©crite dans le contexte. `MediaFile` doit avoir un hash unique."*

### 3. Logique de Gestion de Fichiers
- [ ] Cr√©er les fonctions CRUD : `add_media` (check hash, incr√©mente ref_count) et `delete_media` (d√©cr√©mente, supprime fichier si 0).

---

## ‚öôÔ∏è PHASE 3 : Le Moteur de T√©l√©chargement

**Objectif :** T√©l√©charger proprement et convertir pour le Web.

### 1. Worker System
- [ ] Mettre en place Arq (avec Redis) pour les t√¢ches en arri√®re-plan.

### 2. Le Wrapper yt-dlp & FFmpeg
**Prompt IA sugg√©r√© :**
> *"Cr√©e une task Python qui prend une URL et des cookies. Elle doit : 1. T√©l√©charger avec yt-dlp. 2. V√©rifier le format. 3. Si ce n'est pas du MP4/H264, lancer une conversion FFmpeg. 4. Sauvegarder sur le NAS et mettre √† jour la BDD."*

**Points de vigilance :**
- V√©rifie que l'IA g√®re les erreurs (try/except) pour ne pas crasher le worker.
- Le transcodage est lourd : surveille le CPU de ton LXC lors des tests.

---

## üé® PHASE 4 : Le Frontend (Interface)

**Objectif :** Voir ce qu'on a t√©l√©charg√©.

### 1. Setup
- [ ] Initialiser React + Vite + Tailwind + Shadcn/ui.

### 2. Features
- [ ] **Dashboard :** Connecter via WebSocket ou Polling pour voir l'avancement des t√©l√©chargements.
- [ ] **Player Vid√©o :** Un simple tag `<video>` HTML5 suffit car on a forc√© le MP4 au backend.
- [ ] **Biblioth√®que :** Affichage des dossiers virtuels.

---

## üß© PHASE 5 : L'Extension Navigateur

**Objectif :** Envoyer les cookies et les liens.

- [ ] Cr√©er le `manifest.json` (V3).
- [ ] Popup : Bouton "Extract Cookies" (envoi au backend chiffr√©).
- [ ] Context Menu : "Download to MediaFetcher".

---

## ü§ñ GUIDE DE SURVIE IA : Comment leur parler ?

### R√®gle d'Or : Le "Priming"
Avant de demander du code complexe, rappelle toujours le contexte si tu n'es pas s√ªr que l'Agent l'a lu.

### Quand utiliser Gemini (Google) ?
Utilise-le en **Mode Agent** pour l'architecture et les liens entre fichiers.
*Exemple :* "J'ai modifi√© le mod√®le `MediaFile` dans le backend. Mets √† jour les types TypeScript dans le frontend pour correspondre."

### Quand utiliser Codex (OpenAI) ?
Utilise-le pour des algorithmes purs ou des scripts pr√©cis.
*Exemple :* "√âcris une fonction Python optimis√©e pour calculer le SHA256 d'un gros fichier par chunks pour ne pas saturer la RAM."

### Les Mots-Cl√©s Magiques √† utiliser dans tes prompts
- **"Strictly follow GEMINI.md"** : Pour √©viter les hallucinations.
- **"Alpine compatible"** : Pour √©viter les erreurs d'installation syst√®me.
- **"Self-hosted context"** : Pour qu'il ne te propose pas AWS S3 ou Cloudinary.
- **"Reference Counting Logic"** : √Ä r√©p√©ter d√®s qu'on touche √† la suppression.

---

## üìù Check-list de D√©marrage Rapide

1.  Cr√©er les fichiers `.md` de doc.
2.  Configurer VS Code (Extensions).
3.  Lancer le prompt pour le `docker-compose.yml`.
4.  D√©marrer les conteneurs : `docker compose up -d`.
5.  V√©rifier que Postgres et Redis tournent.
6.  Coder !